{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6fd0fe8-66f2-4c07-8dd6-05e08328a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40248762-40bd-49c9-8744-5a84d9eab1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from modules import NormedConv2d,BcosConv2d,NormedLinear\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bc3e722-11e6-41fc-b292-3d16ef6f8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\tdevice = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "\tdevice = torch.device(\"mps\")\n",
    "else:\n",
    "\tdevice = torch.device(\"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fea7d2e-f63a-439b-9779-84555057d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './processed_female_cells/'\n",
    "files = os.listdir(root_path)\n",
    "files = [i for i in files if not i== '.DS_Store']\n",
    "file_labels = [i.split(' ')[2] for i in files]\n",
    "label_string_to_numreic = {'Mutant':0, 'Control':1, 'Treated':2}\n",
    "labels = [label_string_to_numreic[i] for i in file_labels]\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(files,labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "image_paths_train = []\n",
    "labels_train = []\n",
    "for i,ele in enumerate(train_files):\n",
    "    image_path = os.listdir(root_path+ele)\n",
    "    image_path = [k for k in image_path if k.endswith('.png')]\n",
    "    for k in image_path:\n",
    "        image_paths_train.append(root_path+ele+'/'+k)\n",
    "        labels_train.append(train_labels[i])\n",
    "\n",
    "image_paths_test = []\n",
    "labels_test = []\n",
    "for i,ele in enumerate(test_files):\n",
    "    image_path = os.listdir(root_path+ele)\n",
    "    image_path = [k for k in image_path if k.endswith('.png')]\n",
    "    for k in image_path:\n",
    "        image_paths_test.append(root_path+ele+'/'+k)\n",
    "        labels_test.append(test_labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59c0b0f-e420-42fd-aa2b-2b40107fdc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(27000,), (27000,), (7500,), (7500,)]\n",
      "(array([0, 1, 2]), array([9000, 9000, 9000])) (array([0, 1, 2]), array([1500, 3000, 3000]))\n"
     ]
    }
   ],
   "source": [
    "print ([np.shape(i) for i in [image_paths_train, labels_train, image_paths_test, labels_test]])\n",
    "print (np.unique(labels_train,return_counts=True),np.unique(labels_test,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ff34d08-cda6-4c86-8958-7c92994448b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)        \n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0202a10e-cfbd-404d-b02e-5ecb7c60540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/helium/.cache/torch/hub/B-cos_B-cos-v2_main\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('B-cos/B-cos-v2', 'vitc_l_patch1_14', pretrained=True)\n",
    "model[0].linear_head.linear.linear = NormedLinear(1024,2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04523645-8708-46a9-abd9-d46c151fc123",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = model.transform #transforms.Compose([transforms.Resize((224, 224)),transforms.ToTensor()])\n",
    "\n",
    "train_dataset = CustomDataset(image_paths_train, labels_train, transform=transform)\n",
    "test_dataset = CustomDataset(image_paths_test, labels_test, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1765389c-2741-43a0-bb62-6f3b3eb4b10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 6, 224, 224]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print (images.shape,labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40e2f7bd-975d-48a8-82c6-4bd642303e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4cf75a-8b88-4d4b-8e9b-90b86969144e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load('./model_2.pth',map_location=torch.device(device))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b9ce641-4b1c-4416-aebf-d7b36f85716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 235/235 [03:15<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(model, data_loader=test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)  # labels are now integers\n",
    "            outputs = model(inputs)\n",
    "            # No activation needed; directly take the argmax of the logits\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total * 100.0\n",
    "    return accuracy\n",
    "print (calculate_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10415867-32e1-4222-9a11-142330597c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "test_log = 0\n",
    "log = []\n",
    "counter = 0\n",
    "for epoch in range(epochs):\n",
    "    counter +=1\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.to(device))\n",
    "        #outputs = sigmoid(outputs.to(device))\n",
    "        labels = labels.to(device)\n",
    "        loss = criterion(outputs.to(device), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    test_acc = calculate_accuracy(model,test_loader)\n",
    "    print (test_acc)\n",
    "    log.append(test_acc)\n",
    "    if test_acc>test_log:\n",
    "        counter = 0\n",
    "        test_log = test_acc\n",
    "        #torch.save(model.state_dict(), './model_2.pth')\n",
    "    if counter > 40:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1850fae-c423-4158-8731-c2d0b0d8a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = calculate_accuracy(model,test_loader)\n",
    "print (test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9685354-3a14-4b24-9fe2-bae338c4bdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
